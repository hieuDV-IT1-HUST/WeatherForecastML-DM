{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc44ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(os.getcwd()).resolve().parent.parent\n",
    "DATA = ROOT / \"data\"\n",
    "TRAINED_DATA = DATA / \"trained_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ecb5353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_redundant_mean_features(features):\n",
    "    \"\"\"\n",
    "    Loại bỏ các đặc trưng *_mean nếu đã có cả *_min và *_max tương ứng.\n",
    "\n",
    "    Args:\n",
    "        features (list): Danh sách tên các đặc trưng đã chọn.\n",
    "\n",
    "    Returns:\n",
    "        list: Danh sách đặc trưng sau khi loại bỏ các *_mean dư thừa.\n",
    "    \"\"\"\n",
    "    features_set = set(features)\n",
    "    cleaned_features = features.copy()\n",
    "\n",
    "    # Tìm tất cả các nhóm có dạng <prefix>_min, <prefix>_mean, <prefix>_max\n",
    "    for feature in features:\n",
    "        if feature.endswith(\"_mean\"):\n",
    "            prefix = feature[:-5]  # Bỏ \"_mean\"\n",
    "            min_feat = f\"{prefix}_min\"\n",
    "            max_feat = f\"{prefix}_max\"\n",
    "            if min_feat in features_set and max_feat in features_set:\n",
    "                print(f\"[INFO] Detected redundant features: {min_feat}, {feature}, {max_feat}. Removing {feature}.\")\n",
    "                cleaned_features.remove(feature)\n",
    "                print(f\"[INFO] Removed redundant mean feature: {feature}\")\n",
    "\n",
    "    return cleaned_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42cc4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Running features filtering for target: temperature_2m\n",
      "[INFO] The number of remaining features after proxying: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\MyProject\\School_Projects\\WeatherForecastML-DM\\.venv\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Detecting redundant features...\n",
      "[INFO] Final selected features: ['boundary_layer_height', 'cloud_cover', 'cloud_cover_high', 'cloud_cover_low', 'cloud_cover_mid', 'is_day', 'season_cos', 'season_sin', 'soil_moisture_100_to_255cm', 'soil_moisture_28_to_100cm', 'sunshine_duration', 'wind_direction_100m_sin', 'wind_gusts_10m']\n",
      "[INFO] Saved all artifacts to: C:\\Users\\ADMIN\\MyProject\\School_Projects\\WeatherForecastML-DM\\data\\trained_data\\singleoutput\\temperature_2m\n",
      "\n",
      "[INFO] Running features filtering for target: apparent_temperature\n",
      "[INFO] The number of remaining features after proxying: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\MyProject\\School_Projects\\WeatherForecastML-DM\\.venv\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Detecting redundant features...\n",
      "[INFO] Final selected features: ['boundary_layer_height', 'cloud_cover', 'cloud_cover_high', 'cloud_cover_low', 'cloud_cover_mid', 'is_day', 'season_cos', 'season_sin', 'soil_moisture_100_to_255cm', 'soil_moisture_28_to_100cm', 'sunshine_duration', 'wind_direction_100m_sin', 'wind_gusts_10m']\n",
      "[INFO] Saved all artifacts to: C:\\Users\\ADMIN\\MyProject\\School_Projects\\WeatherForecastML-DM\\data\\trained_data\\singleoutput\\apparent_temperature\n",
      "\n",
      "[INFO] Running features filtering for target: relative_humidity_2m\n",
      "[INFO] The number of remaining features after proxying: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\MyProject\\School_Projects\\WeatherForecastML-DM\\.venv\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     37\u001b[39m vif = pd.DataFrame()\n\u001b[32m     38\u001b[39m vif[\u001b[33m\"\u001b[39m\u001b[33mfeature\u001b[39m\u001b[33m\"\u001b[39m] = safe_features\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m vif[\u001b[33m\"\u001b[39m\u001b[33mVIF\u001b[39m\u001b[33m\"\u001b[39m] = [\u001b[43mvariance_inflation_factor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X_scaled.shape[\u001b[32m1\u001b[39m])]\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Giữ lại những biến có VIF thấp hơn ngưỡng < 10\u001b[39;00m\n\u001b[32m     42\u001b[39m vif_selected = vif[vif[\u001b[33m\"\u001b[39m\u001b[33mVIF\u001b[39m\u001b[33m\"\u001b[39m] < \u001b[32m10\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mfeature\u001b[39m\u001b[33m\"\u001b[39m].tolist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\MyProject\\School_Projects\\WeatherForecastML-DM\\.venv\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:196\u001b[39m, in \u001b[36mvariance_inflation_factor\u001b[39m\u001b[34m(exog, exog_idx)\u001b[39m\n\u001b[32m    194\u001b[39m mask = np.arange(k_vars) != exog_idx\n\u001b[32m    195\u001b[39m x_noti = exog[:, mask]\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m r_squared_i = \u001b[43mOLS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_noti\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.rsquared\n\u001b[32m    197\u001b[39m vif = \u001b[32m1.\u001b[39m / (\u001b[32m1.\u001b[39m - r_squared_i)\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m vif\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\MyProject\\School_Projects\\WeatherForecastML-DM\\.venv\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:333\u001b[39m, in \u001b[36mRegressionModel.fit\u001b[39m\u001b[34m(self, method, cov_type, cov_kwds, use_t, **kwargs)\u001b[39m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mpinv\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpinv_wexog\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    330\u001b[39m             \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnormalized_cov_params\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    331\u001b[39m             \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrank\u001b[39m\u001b[33m'\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m         \u001b[38;5;28mself\u001b[39m.pinv_wexog, singular_values = \u001b[43mpinv_extended\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwexog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    334\u001b[39m         \u001b[38;5;28mself\u001b[39m.normalized_cov_params = np.dot(\n\u001b[32m    335\u001b[39m             \u001b[38;5;28mself\u001b[39m.pinv_wexog, np.transpose(\u001b[38;5;28mself\u001b[39m.pinv_wexog))\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# Cache these singular values for use later.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\MyProject\\School_Projects\\WeatherForecastML-DM\\.venv\\Lib\\site-packages\\statsmodels\\tools\\tools.py:264\u001b[39m, in \u001b[36mpinv_extended\u001b[39m\u001b[34m(x, rcond)\u001b[39m\n\u001b[32m    262\u001b[39m x = np.asarray(x)\n\u001b[32m    263\u001b[39m x = x.conjugate()\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m u, s, vt = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m s_orig = np.copy(s)\n\u001b[32m    266\u001b[39m m = u.shape[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\MyProject\\School_Projects\\WeatherForecastML-DM\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:1812\u001b[39m, in \u001b[36msvd\u001b[39m\u001b[34m(a, full_matrices, compute_uv, hermitian)\u001b[39m\n\u001b[32m   1808\u001b[39m signature = \u001b[33m'\u001b[39m\u001b[33mD->DdD\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33md->ddd\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1809\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call=_raise_linalgerror_svd_nonconvergence,\n\u001b[32m   1810\u001b[39m               invalid=\u001b[33m'\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m'\u001b[39m, over=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, divide=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1811\u001b[39m               under=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1812\u001b[39m     u, s, vh = \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1813\u001b[39m u = u.astype(result_t, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1814\u001b[39m s = s.astype(_realType(result_t), copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "METHOD = \"SingleOutput\"\n",
    "\n",
    "# Load dữ liệu\n",
    "df = pd.read_csv(\"../../data/processed/clean_hourly_weather.csv\")\n",
    "\n",
    "# Danh sách các biến mục tiêu\n",
    "target_variables = [\n",
    "    \"temperature_2m\",\n",
    "    \"apparent_temperature\",\n",
    "    \"relative_humidity_2m\",\n",
    "    \"wind_speed_10m\",\n",
    "    \"wind_direction_10m_sin\",\n",
    "    \"wind_direction_10m_cos\",\n",
    "    \"rain\",\n",
    "    \"shortwave_radiation\"\n",
    "]\n",
    "\n",
    "# Duyệt qua từng mục tiêu\n",
    "for target_variable in target_variables:\n",
    "    print(f\"\\n[INFO] Running features filtering for target: {target_variable}\")\n",
    "    # Tính tương quan với biến mục tiêu\n",
    "    corr_with_target = df.corr(numeric_only=True)[target_variable].drop(target_variable)\n",
    "\n",
    "    # Giữ lại các biến có tương quan < 0.99\n",
    "    safe_features = corr_with_target[corr_with_target.abs() < 0.99].index.tolist()\n",
    "\n",
    "    print(f\"[INFO] The number of remaining features after proxying: {len(safe_features)}\")\n",
    "\n",
    "    # Chia dữ liệu train/test theo thời gian: 80% train, 20% test\n",
    "    split_index = int(len(df) * 0.8)\n",
    "    train_df = df.iloc[:split_index]\n",
    "    test_df = df.iloc[split_index:]\n",
    "    \n",
    "    X_corr = df[safe_features]\n",
    "    X_scaled = StandardScaler().fit_transform(X_corr)\n",
    "\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"feature\"] = safe_features\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]\n",
    "\n",
    "    # Giữ lại những biến có VIF thấp hơn ngưỡng < 10\n",
    "    vif_selected = vif[vif[\"VIF\"] < 10][\"feature\"].tolist()\n",
    "\n",
    "    # Gộp vào kết quả cuối cùng\n",
    "    selected_features = sorted(set(vif_selected + [\"season_sin\", \"season_cos\"]))\n",
    "    print(\"[INFO] Final selected features:\", selected_features)\n",
    "\n",
    "    # Tách lại theo đặc trưng được chọn cho train/test\n",
    "    X_train = train_df[selected_features]\n",
    "    X_test = test_df[selected_features]\n",
    "    y_train = train_df[target_variable]\n",
    "    y_test = test_df[target_variable]\n",
    "\n",
    "    # Tạo pipeline chính\n",
    "    preprocessor = ColumnTransformer(transformers=[(\"num\", StandardScaler(), selected_features)])\n",
    "    target_output_dir = TRAINED_DATA / METHOD.lower() / target_variable\n",
    "    target_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Lưu dữ liệu\n",
    "    joblib.dump(X_train, target_output_dir / \"X_train.pkl\")\n",
    "    joblib.dump(X_test, target_output_dir / \"X_test.pkl\")\n",
    "    joblib.dump(y_train, target_output_dir / \"y_train.pkl\")\n",
    "    joblib.dump(y_test, target_output_dir / \"y_test.pkl\")\n",
    "    joblib.dump(preprocessor, target_output_dir / \"preprocessor.pkl\")\n",
    "    with open(target_output_dir / \"selected_features.json\", \"w\") as f:\n",
    "        json.dump(selected_features, f, indent=2)\n",
    "\n",
    "    print(f\"[INFO] Saved all artifacts to: {target_output_dir}\")\n",
    "    \n",
    "    test_df = test_df.copy()\n",
    "    test_df[\"date\"] = df.iloc[split_index:][\"date\"].values\n",
    "    test_df[target_variable] = y_test.values\n",
    "    test_df.to_csv(target_output_dir / \"test_df.csv\", index=False)\n",
    "\n",
    "print(\"\\n✅ DONE: Feature selection and saving complete for all target variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d281a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Detecting redundant features...\n",
      "[INFO] Final selected features: ['boundary_layer_height', 'cloud_cover', 'cloud_cover_high', 'cloud_cover_low', 'cloud_cover_mid', 'is_day', 'precipitation', 'season_cos', 'season_sin', 'soil_moisture_100_to_255cm', 'soil_moisture_28_to_100cm', 'sunshine_duration', 'total_column_integrated_water_vapour', 'wind_direction_100m_cos', 'wind_direction_100m_sin', 'wind_gusts_10m', 'wind_speed_100m']\n",
      "[INFO] Saved all artifacts to: C:\\Users\\ADMIN\\MyProject\\School_Projects\\WeatherForecastML-DM\\data\\trained_data\\hourly\n"
     ]
    }
   ],
   "source": [
    "METHOD = \"MultiOutput\"\n",
    "\n",
    "df = pd.read_csv(\"../../data/processed/clean_hourly_weather.csv\")\n",
    "\n",
    "target_variables = [\n",
    "    \"temperature_2m\",\n",
    "    \"apparent_temperature\",\n",
    "    \"relative_humidity_2m\",\n",
    "    \"wind_speed_10m\",\n",
    "    \"wind_direction_10m_sin\",\n",
    "    \"wind_direction_10m_cos\",\n",
    "    \"rain\",\n",
    "    \"shortwave_radiation\"\n",
    "]\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "feature_candidates = [f for f in numerical_cols if f not in target_variables]\n",
    "\n",
    "corr_matrix = df[target_variables + feature_candidates].corr(numeric_only=True)\n",
    "\n",
    "# Lấy chỉ phần tương quan giữa đặc trưng và mục tiêu\n",
    "corr_features_targets = corr_matrix.loc[feature_candidates, target_variables]\n",
    "\n",
    "max_corr = corr_features_targets.abs().max(axis=1)\n",
    "\n",
    "selected_features = max_corr[max_corr < 0.995].index.tolist()\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(df[selected_features])\n",
    "vif = pd.DataFrame()\n",
    "vif[\"feature\"] = selected_features\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]\n",
    "\n",
    "# Loại các feature có VIF >= 10\n",
    "vif_selected = vif[vif[\"VIF\"] < 10][\"feature\"].tolist()\n",
    "\n",
    "selected_features = sorted(set(vif_selected + [\"season_sin\", \"season_cos\"]))\n",
    "print(f\"[INFO] Detecting redundant features...\")\n",
    "selected_features = remove_redundant_mean_features(selected_features)\n",
    "print(\"[INFO] Final selected features:\", selected_features)\n",
    "\n",
    "split_index = int(len(df) * 0.8)\n",
    "train_df = df.iloc[:split_index]\n",
    "test_df = df.iloc[split_index:]\n",
    "\n",
    "# Tách lại theo đặc trưng được chọn cho train/test\n",
    "X_train = train_df[selected_features]\n",
    "X_test = test_df[selected_features]\n",
    "y_train = train_df[target_variables]\n",
    "y_test = test_df[target_variables]\n",
    "\n",
    "# Tạo pipeline chính\n",
    "preprocessor = ColumnTransformer(transformers=[(\"num\", StandardScaler(), selected_features)])\n",
    "target_output_dir = TRAINED_DATA / METHOD.lower()\n",
    "target_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Lưu dữ liệu\n",
    "joblib.dump(X_train, target_output_dir / \"X_train.pkl\")\n",
    "joblib.dump(X_test, target_output_dir / \"X_test.pkl\")\n",
    "joblib.dump(y_train, target_output_dir / \"y_train.pkl\")\n",
    "joblib.dump(y_test, target_output_dir / \"y_test.pkl\")\n",
    "joblib.dump(preprocessor, target_output_dir / \"preprocessor.pkl\")\n",
    "with open(target_output_dir / \"selected_features.json\", \"w\") as f:\n",
    "    json.dump(selected_features, f, indent=2)\n",
    "\n",
    "print(f\"[INFO] Saved all artifacts to: {target_output_dir}\")\n",
    "\n",
    "test_df = test_df.copy()\n",
    "test_df[\"date\"] = df.iloc[split_index:][\"date\"].values\n",
    "test_df[target_variables] = y_test.values\n",
    "test_df.to_csv(target_output_dir / \"test_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
