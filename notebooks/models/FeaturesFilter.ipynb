{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc44ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(os.getcwd()).resolve().parent.parent\n",
    "DATA = ROOT / \"data\"\n",
    "TRAINED_DATA = DATA / \"trained_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ecb5353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_redundant_mean_features(features):\n",
    "    \"\"\"\n",
    "    Loại bỏ các đặc trưng *_mean nếu đã có cả *_min và *_max tương ứng.\n",
    "\n",
    "    Args:\n",
    "        features (list): Danh sách tên các đặc trưng đã chọn.\n",
    "\n",
    "    Returns:\n",
    "        list: Danh sách đặc trưng sau khi loại bỏ các *_mean dư thừa.\n",
    "    \"\"\"\n",
    "    features_set = set(features)\n",
    "    cleaned_features = features.copy()\n",
    "\n",
    "    # Tìm tất cả các nhóm có dạng <prefix>_min, <prefix>_mean, <prefix>_max\n",
    "    for feature in features:\n",
    "        if feature.endswith(\"_mean\"):\n",
    "            prefix = feature[:-5]  # Bỏ \"_mean\"\n",
    "            min_feat = f\"{prefix}_min\"\n",
    "            max_feat = f\"{prefix}_max\"\n",
    "            if min_feat in features_set and max_feat in features_set:\n",
    "                print(f\"[INFO] Detected redundant features: {min_feat}, {feature}, {max_feat}. Removing {feature}.\")\n",
    "                cleaned_features.remove(feature)\n",
    "                print(f\"[INFO] Removed redundant mean feature: {feature}\")\n",
    "\n",
    "    return cleaned_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a42cc4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Running features filtering for target: temperature_2m\n",
      "[INFO] The number of remaining features after proxying: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\MyProject\\School_Projects\\WeatherForecastML-DM\\.venv\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Final selected features: ['boundary_layer_height', 'cloud_cover', 'cloud_cover_high', 'cloud_cover_low', 'cloud_cover_mid', 'is_day', 'season_cos', 'season_sin', 'soil_moisture_100_to_255cm', 'soil_moisture_28_to_100cm', 'sunshine_duration', 'wind_direction_100m_sin', 'wind_gusts_10m']\n",
      "[INFO] Saved all artifacts to: C:\\Users\\ADMIN\\MyProject\\School_Projects\\WeatherForecastML-DM\\data\\trained_data\\singleoutput\\temperature_2m\n",
      "\n",
      "✅ DONE: Feature selection and saving complete for all target variables.\n"
     ]
    }
   ],
   "source": [
    "METHOD = \"SingleOutput\"\n",
    "\n",
    "# Load dữ liệu\n",
    "df = pd.read_csv(\"../../data/processed/clean_hourly_weather.csv\")\n",
    "\n",
    "# Danh sách các biến mục tiêu\n",
    "target_variables = [\n",
    "    \"temperature_2m\",\n",
    "    # \"apparent_temperature\",\n",
    "    # \"relative_humidity_2m\",\n",
    "    # \"wind_speed_10m\",\n",
    "    # \"wind_direction_10m_sin\",\n",
    "    # \"wind_direction_10m_cos\",\n",
    "    # \"rain\",\n",
    "    # \"shortwave_radiation\"\n",
    "]\n",
    "\n",
    "# Duyệt qua từng mục tiêu\n",
    "for target_variable in target_variables:\n",
    "    print(f\"\\n[INFO] Running features filtering for target: {target_variable}\")\n",
    "    # Tính tương quan với biến mục tiêu\n",
    "    corr_with_target = df.corr(numeric_only=True)[target_variable].drop(target_variable)\n",
    "\n",
    "    # Giữ lại các biến có tương quan < 0.99\n",
    "    safe_features = corr_with_target[corr_with_target.abs() < 0.99].index.tolist()\n",
    "\n",
    "    print(f\"[INFO] The number of remaining features after proxying: {len(safe_features)}\")\n",
    "\n",
    "    # Chia dữ liệu train/test theo thời gian: 80% train, 20% test\n",
    "    split_index = int(len(df) * 0.8)\n",
    "    train_df = df.iloc[:split_index]\n",
    "    test_df = df.iloc[split_index:]\n",
    "    \n",
    "    X_corr = df[safe_features]\n",
    "    X_scaled = StandardScaler().fit_transform(X_corr)\n",
    "\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"feature\"] = safe_features\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]\n",
    "\n",
    "    # Giữ lại những biến có VIF thấp hơn ngưỡng < 10\n",
    "    vif_selected = vif[vif[\"VIF\"] < 10][\"feature\"].tolist()\n",
    "\n",
    "    # Gộp vào kết quả cuối cùng\n",
    "    selected_features = sorted(set(vif_selected + [\"season_sin\", \"season_cos\"]))\n",
    "    print(\"[INFO] Final selected features:\", selected_features)\n",
    "\n",
    "    # Tách lại theo đặc trưng được chọn cho train/test\n",
    "    X_train = train_df[selected_features]\n",
    "    X_test = test_df[selected_features]\n",
    "    y_train = train_df[target_variable]\n",
    "    y_test = test_df[target_variable]\n",
    "\n",
    "    # Tạo pipeline chính\n",
    "    preprocessor = ColumnTransformer(transformers=[(\"num\", StandardScaler(), selected_features)])\n",
    "    target_output_dir = TRAINED_DATA / METHOD.lower() / target_variable\n",
    "    target_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Lưu dữ liệu\n",
    "    joblib.dump(X_train, target_output_dir / \"X_train.pkl\")\n",
    "    joblib.dump(X_test, target_output_dir / \"X_test.pkl\")\n",
    "    joblib.dump(y_train, target_output_dir / \"y_train.pkl\")\n",
    "    joblib.dump(y_test, target_output_dir / \"y_test.pkl\")\n",
    "    joblib.dump(preprocessor, target_output_dir / \"preprocessor.pkl\")\n",
    "    with open(target_output_dir / \"selected_features.json\", \"w\") as f:\n",
    "        json.dump(selected_features, f, indent=2)\n",
    "\n",
    "    print(f\"[INFO] Saved all artifacts to: {target_output_dir}\")\n",
    "    \n",
    "    test_df = test_df.copy()\n",
    "    test_df[\"date\"] = df.iloc[split_index:][\"date\"].values\n",
    "    test_df[target_variable] = y_test.values\n",
    "    test_df.to_csv(target_output_dir / \"test_df.csv\", index=False)\n",
    "\n",
    "print(\"\\n✅ DONE: Feature selection and saving complete for all target variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d281a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Detecting redundant features...\n",
      "[INFO] Final selected features: ['boundary_layer_height', 'cloud_cover', 'cloud_cover_high', 'cloud_cover_low', 'cloud_cover_mid', 'is_day', 'precipitation', 'season_cos', 'season_sin', 'soil_moisture_100_to_255cm', 'soil_moisture_28_to_100cm', 'sunshine_duration', 'total_column_integrated_water_vapour', 'wind_direction_100m_cos', 'wind_direction_100m_sin', 'wind_gusts_10m', 'wind_speed_100m']\n",
      "[INFO] Saved all artifacts to: C:\\Users\\ADMIN\\MyProject\\School_Projects\\WeatherForecastML-DM\\data\\trained_data\\hourly\n"
     ]
    }
   ],
   "source": [
    "METHOD = \"MultiOutput\"\n",
    "\n",
    "df = pd.read_csv(\"../../data/processed/clean_hourly_weather.csv\")\n",
    "\n",
    "target_variables = [\n",
    "    \"temperature_2m\",\n",
    "    \"apparent_temperature\",\n",
    "    \"relative_humidity_2m\",\n",
    "    \"wind_speed_10m\",\n",
    "    \"wind_direction_10m_sin\",\n",
    "    \"wind_direction_10m_cos\",\n",
    "    \"rain\",\n",
    "    \"shortwave_radiation\"\n",
    "]\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "feature_candidates = [f for f in numerical_cols if f not in target_variables]\n",
    "\n",
    "corr_matrix = df[target_variables + feature_candidates].corr(numeric_only=True)\n",
    "\n",
    "# Lấy chỉ phần tương quan giữa đặc trưng và mục tiêu\n",
    "corr_features_targets = corr_matrix.loc[feature_candidates, target_variables]\n",
    "\n",
    "max_corr = corr_features_targets.abs().max(axis=1)\n",
    "\n",
    "selected_features = max_corr[max_corr < 0.995].index.tolist()\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(df[selected_features])\n",
    "vif = pd.DataFrame()\n",
    "vif[\"feature\"] = selected_features\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]\n",
    "\n",
    "# Loại các feature có VIF >= 10\n",
    "vif_selected = vif[vif[\"VIF\"] < 10][\"feature\"].tolist()\n",
    "\n",
    "selected_features = sorted(set(vif_selected + [\"season_sin\", \"season_cos\"]))\n",
    "print(f\"[INFO] Detecting redundant features...\")\n",
    "selected_features = remove_redundant_mean_features(selected_features)\n",
    "print(\"[INFO] Final selected features:\", selected_features)\n",
    "\n",
    "split_index = int(len(df) * 0.8)\n",
    "train_df = df.iloc[:split_index]\n",
    "test_df = df.iloc[split_index:]\n",
    "\n",
    "# Tách lại theo đặc trưng được chọn cho train/test\n",
    "X_train = train_df[selected_features]\n",
    "X_test = test_df[selected_features]\n",
    "y_train = train_df[target_variables]\n",
    "y_test = test_df[target_variables]\n",
    "\n",
    "# Tạo pipeline chính\n",
    "preprocessor = ColumnTransformer(transformers=[(\"num\", StandardScaler(), selected_features)])\n",
    "target_output_dir = TRAINED_DATA / METHOD.lower()\n",
    "target_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Lưu dữ liệu\n",
    "joblib.dump(X_train, target_output_dir / \"X_train.pkl\")\n",
    "joblib.dump(X_test, target_output_dir / \"X_test.pkl\")\n",
    "joblib.dump(y_train, target_output_dir / \"y_train.pkl\")\n",
    "joblib.dump(y_test, target_output_dir / \"y_test.pkl\")\n",
    "joblib.dump(preprocessor, target_output_dir / \"preprocessor.pkl\")\n",
    "with open(target_output_dir / \"selected_features.json\", \"w\") as f:\n",
    "    json.dump(selected_features, f, indent=2)\n",
    "\n",
    "print(f\"[INFO] Saved all artifacts to: {target_output_dir}\")\n",
    "\n",
    "test_df = test_df.copy()\n",
    "test_df[\"date\"] = df.iloc[split_index:][\"date\"].values\n",
    "test_df[target_variables] = y_test.values\n",
    "test_df.to_csv(target_output_dir / \"test_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
